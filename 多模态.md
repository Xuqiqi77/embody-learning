# Mamba
RNN的训练过程中当前时间步依赖于前一时间步的计算，因此不能并行计算，效率非常低，而结构并不复杂，所以推理速度还可以（线性计算）；Transformer训练过程是矩阵运算，其训练是可以并行计算的，效率比较高，但是推理过程是一个词一个词去进行矩阵运算（即已经生成了一些token，当生成下一个token时，仍然需要重新计算整个序列的注意力），效率比较低。

